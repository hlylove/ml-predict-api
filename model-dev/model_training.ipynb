{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSSvXBlyQMMo",
        "outputId": "84cd79dd-23db-499b-f6b8-900fc43550b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       timestamp  visitorid event  itemid  transactionid\n",
            "0  1433221332117     257597  view  355908            NaN\n",
            "1  1433224214164     992329  view  248676            NaN\n",
            "2  1433221999827     111016  view  318965            NaN\n",
            "3  1433221955914     483717  view  253185            NaN\n",
            "4  1433221337106     951259  view  367447            NaN\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 上传数据集文件\n",
        "events = pd.read_csv('events.csv')\n",
        "print(events.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 转换时间戳为可读格式\n",
        "events['timestamp'] = pd.to_datetime(events['timestamp'], unit='ms')\n",
        "\n",
        "# 保留活跃用户\n",
        "active_users = events['visitorid'].value_counts()\n",
        "active_users = active_users[active_users > 10].index\n",
        "events = events[events['visitorid'].isin(active_users)]\n",
        "\n",
        "# 按时间排序\n",
        "events = events.sort_values(['visitorid', 'timestamp'])\n",
        "\n",
        "# 将 event 类型转为数字\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "events['event_encoded'] = label_encoder.fit_transform(events['event'])\n",
        "\n",
        "event_to_idx = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "print(\"事件类别映射：\", event_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddUEJtmWSTwb",
        "outputId": "87b72b60-6e03-4e45-fcc6-c7f6d88dde42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "事件类别映射： {'addtocart': 0, 'transaction': 1, 'view': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 5  # 使用过去5步预测下一步\n",
        "\n",
        "X, y = [], []\n",
        "\n",
        "for visitor_id, group in events.groupby('visitorid'):\n",
        "    seq = group['event_encoded'].tolist()\n",
        "    for i in range(len(seq) - SEQ_LEN):\n",
        "        X.append(seq[i:i+SEQ_LEN])\n",
        "        y.append(seq[i+SEQ_LEN])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"样本数：\", len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRjRuDGyX6xm",
        "outputId": "1de27047-7920-457c-a76f-e7d43bd99e15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "样本数： 448804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_dataset = SequenceDataset(X_train, y_train)\n",
        "val_dataset = SequenceDataset(X_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128)"
      ],
      "metadata": {
        "id": "W8kbucoJYXsX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BehaviorLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        _, (h_n, _) = self.lstm(emb)\n",
        "        out = self.fc(h_n[-1])\n",
        "        return out\n",
        "\n",
        "input_dim = len(label_encoder.classes_)  # event种类数\n",
        "model = BehaviorLSTM(input_dim, embedding_dim=32, hidden_dim=64, output_dim=input_dim)"
      ],
      "metadata": {
        "id": "8n1sAlhfYcm7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "            targets.extend(y_batch.numpy())\n",
        "    acc = accuracy_score(targets, preds)\n",
        "    f1 = f1_score(targets, preds, average='macro')\n",
        "    return acc, f1\n",
        "\n",
        "train_losses = []\n",
        "for epoch in range(5):\n",
        "    loss = train(model, train_loader)\n",
        "    acc, f1 = evaluate(model, val_loader)\n",
        "    train_losses.append(loss)\n",
        "    print(f\"Epoch {epoch+1}: Loss={loss:.4f}, Val_Acc={acc:.4f}, F1={f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_n4re3iYgBd",
        "outputId": "c148e8c9-1bc0-442f-bf32-cac14cc8f655"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss=0.2519, Val_Acc=0.9185, F1=0.4837\n",
            "Epoch 2: Loss=0.2518, Val_Acc=0.9191, F1=0.5041\n",
            "Epoch 3: Loss=0.2517, Val_Acc=0.9191, F1=0.5156\n",
            "Epoch 4: Loss=0.2517, Val_Acc=0.9188, F1=0.5170\n",
            "Epoch 5: Loss=0.2516, Val_Acc=0.9190, F1=0.5147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LxhHBc6bSJR",
        "outputId": "1bc1a84a-bf28-436c-c190-87c4a5a62511"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.1)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 模型导出为 ONNX\n",
        "dummy_input = torch.randint(0, input_dim, (1, SEQ_LEN)).to(device)\n",
        "torch.onnx.export(\n",
        "    model, dummy_input, \"behavior_model.onnx\",\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"output\"],\n",
        "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
        "    opset_version=11\n",
        ")\n",
        "print(\"模型已导出为behavior_model.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6m92C4gbDGg",
        "outputId": "86206af2-303c-4ae8-dd04-fa49d3f156bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型已导出为behavior_model.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/onnx/symbolic_opset9.py:4277: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}